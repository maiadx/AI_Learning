
We'll reproduce GPT-2 from scratch (124M).

[![Alt text](https://img.youtube.com/vi/l8pRSuU81PU?si=Beus3pzegDf7rWHa)](https://www.youtube.com/watch?v=l8pRSuU81PU?si=Beus3pzegDf7rWHa)

First, let's do a paper reading of "Language Models Are Unsupervised Multitask Learners":
