
We'll reproduce GPT-2 from scratch (124M).

[![Everything Is AWESOME](https://img.youtube.com/vi/StTqXEQ2l-Y/0.jpg)](https://www.youtube.com/watch?v=StTqXEQ2l-Y "Everything Is AWESOME")

First, let's do a paper reading of "Language Models Are Unsupervised Multitask Learners":
