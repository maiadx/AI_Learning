
We'll reproduce GPT-2 from scratch (124M).

[![IMAGE ALT TEXT](https://youtu.be/l8pRSuU81PU?si=_J0WUWRIduX_9Gan)](https://youtu.be/l8pRSuU81PU?si=_J0WUWRIduX_9Gan)


First, let's do a paper reading of "Language Models Are Unsupervised Multitask Learners":
